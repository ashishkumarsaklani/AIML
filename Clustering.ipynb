{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ashishkumarsaklani/AIML/blob/main/Clustering.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DYJPhCHDGAwk"
      },
      "source": [
        "#importing libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "Rxi4b_yKiWZo"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.impute import KNNImputer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "\n",
        "#from sklearn import linear_model\n",
        "#from sklearn.linear_model import LinearRegression,SGDRegressor,ElasticNet,LogisticRegression\n",
        "#from sklearn.model_selection import train_test_split ,KFold, GridSearchCV\n",
        "#from sklearn.metrics import mean_squared_error, r2_score,accuracy_score,precision_score,recall_score, confusion_matrix,f1_score,roc_auc_score\n",
        "#from sklearn.preprocessing import StandardScaler,MinMaxScaler,PolynomialFeatures\n",
        "#from sklearn.ensemble import RandomForestClassifier\n",
        "#from sklearn.pipeline import Pipeline\n",
        "\n",
        "\n",
        "\n",
        "import re"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tFnY63guiEPo"
      },
      "source": [
        "#Custom Class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GwIvifmiNWq5",
        "outputId": "8da48703-4c81-4810-c87c-b730ec88fb96"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoded List: [1, 2, 2, 3, 1, nan]\n",
            "Encoding Dictionary: {'a': 1, 'b': 2, 'c': 3}\n",
            "Decoded List: ['a', 'b', 'b', 'c', 'a', nan]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "class CustomEncoder:\n",
        "    def __init__(self):\n",
        "        self.encoding_dict = {}  # Dictionary to store encoding mappings\n",
        "        self.counter = 1  # Counter to assign integer encoding values\n",
        "\n",
        "    def fit_transform(self, series):\n",
        "        encoded_list = []  # List to store encoded values\n",
        "\n",
        "        for item in series:\n",
        "            if pd.isna(item):\n",
        "                encoded_list.append(item)\n",
        "            elif item not in self.encoding_dict:\n",
        "                self.encoding_dict[item] = self.counter\n",
        "                self.counter += 1\n",
        "                encoded_list.append(self.encoding_dict[item])\n",
        "            else:\n",
        "                encoded_list.append(self.encoding_dict[item])\n",
        "\n",
        "        return encoded_list, self.encoding_dict\n",
        "\n",
        "    def inverse_transform(self, encoded_list, encoding_dict):\n",
        "        reverse_dict = {v: k for k, v in encoding_dict.items()}  # Reverse the dictionary for decoding\n",
        "        return [reverse_dict[encoded_value] if encoded_value in reverse_dict else encoded_value for encoded_value in encoded_list]\n",
        "\n",
        "# Example usage:\n",
        "encoder = CustomEncoder()\n",
        "input_series = ['a', 'b', 'b', 'c', 'a', np.nan]\n",
        "encoded_list, encoding_dict = encoder.fit_transform(input_series)\n",
        "print(\"Encoded List:\", encoded_list)\n",
        "print(\"Encoding Dictionary:\", encoding_dict)\n",
        "\n",
        "decoded_list = encoder.inverse_transform(encoded_list, encoding_dict)\n",
        "print(\"Decoded List:\", decoded_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "LPJ4sjNeWZqQ"
      },
      "outputs": [],
      "source": [
        "class IQROutlierDetector:\n",
        "\n",
        "  def __init__(self, data, column_name):\n",
        "\n",
        "    self.data = data\n",
        "    self.column_name = column_name\n",
        "\n",
        "  def detect_outliers(self):\n",
        "\n",
        "\n",
        "    if not pd.api.types.is_numeric_dtype(self.data[self.column_name]):\n",
        "      #print(f\"Warning: Column '{self.column_name}' is not numerical. Skipping outlier detection.\")\n",
        "      return None  # Indicate non-numerical column\n",
        "\n",
        "    q1 = self.data[self.column_name].quantile(0.25)\n",
        "    q3 = self.data[self.column_name].quantile(0.75)\n",
        "    iqr = q3 - q1\n",
        "    lower_bound = q1 - 1.5 * iqr\n",
        "    upper_bound = q3 + 1.5 * iqr\n",
        "    outliers = self.data[(self.data[self.column_name] < lower_bound) | (self.data[self.column_name] > upper_bound)].index.tolist()\n",
        "    return outliers\n",
        "\n",
        "  def get_outlier_count(self):\n",
        "\n",
        "    outliers = self.detect_outliers()\n",
        "    if outliers is None:\n",
        "        return 0  # Handle case of non-numerical column\n",
        "    else:\n",
        "        return len(outliers)\n",
        "\n",
        "  def get_outlier_percentage(self):\n",
        "\n",
        "    outlier_count = self.get_outlier_count()\n",
        "    total_data_points = len(self.data)\n",
        "    if total_data_points > 0:\n",
        "        return (outlier_count / total_data_points) * 100\n",
        "    else:\n",
        "        return 0  # Handle case of empty data\n",
        "\n",
        "  def drop_outliers(self):\n",
        "\n",
        "    outliers = self.detect_outliers()\n",
        "    if outliers is None:\n",
        "        return self.data  # Return original data if column is not numerical\n",
        "    else:\n",
        "        return self.data.drop(outliers)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OVMFR4BcGNRv"
      },
      "source": [
        "#importing data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kvbDBZxDibz9",
        "outputId": "5cef008a-55b7-4b86-94cf-d8da39d80bb5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 205843 entries, 0 to 205842\n",
            "Data columns (total 7 columns):\n",
            " #   Column            Non-Null Count   Dtype  \n",
            "---  ------            --------------   -----  \n",
            " 0   Unnamed: 0        205843 non-null  int64  \n",
            " 1   company_hash      205799 non-null  object \n",
            " 2   email_hash        205843 non-null  object \n",
            " 3   orgyear           205757 non-null  float64\n",
            " 4   ctc               205843 non-null  int64  \n",
            " 5   job_position      153281 non-null  object \n",
            " 6   ctc_updated_year  205843 non-null  float64\n",
            "dtypes: float64(2), int64(2), object(3)\n",
            "memory usage: 11.0+ MB\n"
          ]
        }
      ],
      "source": [
        "\n",
        "url ='https://d2beiqkhq929f0.cloudfront.net/public_assets/assets/000/002/856/original/scaler_clustering.csv'\n",
        "df = pd.read_csv(url)\n",
        "df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vxDGLAYPGS5T"
      },
      "source": [
        "#renaming column for my convenience"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "ViCw88ue_Q48"
      },
      "outputs": [],
      "source": [
        "df.rename(columns={\n",
        "'Unnamed: 0':'sn',\n",
        "'company_hash':'company',\n",
        "'email_hash':'email',\n",
        "'orgyear':'j_year',\n",
        "'job_position':'position',\n",
        "'ctc_updated_year':'i_year'\n",
        "},inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NYea3eRzn_fw"
      },
      "source": [
        "#encoding with custom funcuon"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D1CioTY_RwLi",
        "outputId": "e87a4f6f-8607-43ea-ff4c-d1c536681203"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sn :0\n",
            "company :44\n",
            "email :0\n",
            "j_year :86\n",
            "ctc :0\n",
            "position :52562\n",
            "i_year :0\n"
          ]
        }
      ],
      "source": [
        "#Now checking for missing values\n",
        "\n",
        "for col in df.columns:\n",
        "   Mi = df[col].isna().sum()\n",
        "   print(f\"{col} :{Mi}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "06uh8B9dii23"
      },
      "outputs": [],
      "source": [
        "input_series = df['position']\n",
        "df['position'], pos_dict = encoder.fit_transform(input_series)\n",
        "\n",
        "input_series = df['company']\n",
        "df['company'], com_dict = encoder.fit_transform(input_series)\n",
        "\n",
        "input_series = df['email']\n",
        "df['email'], ema_dict = encoder.fit_transform(input_series)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AiNXi3S9JZEr"
      },
      "source": [
        "#Missing Values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "2Fm6rMGvdftW"
      },
      "outputs": [],
      "source": [
        "# Fill missing 'company' values based on non-missing values within the same email group\n",
        "#df['company'] = df.groupby('email')['company'].transform(lambda x: x.fillna(method='ffill'))\n",
        "df.dropna(subset= ['company','j_year'],inplace=True,axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YwppJxtmfifx"
      },
      "outputs": [],
      "source": [
        "# Fill missing 'position' values based on non-missing values within the same email group\n",
        "df['position'] = df.groupby('email')['position'].transform(lambda x: x.fillna(method='ffill'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "20sgde3wJh0E"
      },
      "outputs": [],
      "source": [
        "for col in df.columns:\n",
        "   Mi = df[col].isna().sum()\n",
        "   print(f\"{col} :{Mi}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IdNegV1XDXbz"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dF9N8MncQ19W"
      },
      "source": [
        "#Duplicates"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-6wjElvMBnYR"
      },
      "outputs": [],
      "source": [
        "#checking if there are duplicate and total\n",
        "df.duplicated().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_xvN2wyRG_l0"
      },
      "outputs": [],
      "source": [
        "for col in df.columns:\n",
        "   dup = df[col].duplicated().sum()\n",
        "   print(f\"{col} :{dup}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MEnYquUFIDzo"
      },
      "source": [
        "Serial number of the first column does not have any duplicate values and not relevant we can delete"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4CuJSMoxAjFN"
      },
      "outputs": [],
      "source": [
        "df.drop(columns=['sn'],inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kTYV5uhoFc67"
      },
      "outputs": [],
      "source": [
        "df['j_year']=df['j_year'].astype('int32')\n",
        "df['i_year']=df['i_year'].astype('int32')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "59yZLsLtJmfT"
      },
      "source": [
        "Sorting values by email to check if the multiple records of a same employee"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tNI7z-GcJk5A"
      },
      "outputs": [],
      "source": [
        "sorted_df = df.sort_values(by=['email','j_year'])\n",
        "\n",
        "sorted_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CUO8Cv-VLyA2"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Group by hashed email and count the number of records per group\n",
        "email_counts = df.groupby('email').size()\n",
        "\n",
        "# Filter groups with more than 8 record (potential duplicates)\n",
        "duplicate_emails = email_counts[email_counts > 8]\n",
        "\n",
        "# Display the potential duplicate hashed emails along with their counts\n",
        "print(\"Potential Duplicate Hashed Emails:\")\n",
        "print(duplicate_emails)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GMITuvgNRkVy"
      },
      "source": [
        "Appears like count greater than 8 years not very high it's just 3 we can as you the emails are for a person only not a common emails"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x5JBCbRPNAS_"
      },
      "source": [
        "#Outliers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b4Qown1jNEbk"
      },
      "outputs": [],
      "source": [
        "for col in df.columns:\n",
        "  detector = IQROutlierDetector(df, col)\n",
        "  outlier_indices = detector.detect_outliers()\n",
        "  #print(\"Outlier indices:\", outlier_indices)\n",
        "\n",
        "  outlier_count = detector.get_outlier_count()\n",
        "  outlier_percentage = detector.get_outlier_percentage()\n",
        "  if detector.get_outlier_count() > 0 :\n",
        "    print(f\"{col} Number of outliers:\", outlier_count)\n",
        "    print(f\"{col} Percentage of outliers:\", outlier_percentage, \"%\")\n",
        "    df = detector.drop_outliers()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rkAxFd_sR_Du"
      },
      "source": [
        "\n",
        "#using KNN computer to fill up missing values\n",
        "\n",
        "\n",
        "Made small batch to ensure resources are not exhausted\n",
        "\n",
        "\n",
        "Turned category or non intdata to int so knn can work and changed it back"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZJII6eeu4fpS"
      },
      "outputs": [],
      "source": [
        "\n",
        "from sklearn.impute import KNNImputer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Define batch size\n",
        "batch_size = 500\n",
        "\n",
        "# Calculate the total number of batches\n",
        "num_batches = len(df) // batch_size + (1 if len(df) % batch_size != 0 else 0)\n",
        "\n",
        "# Initialize an empty DataFrame to store the imputed data\n",
        "data_filled = pd.DataFrame()\n",
        "\n",
        "# Iterate over each batch\n",
        "for i in range(num_batches):\n",
        "    # Determine the start and end indices for the current batch\n",
        "    start_idx = i * batch_size\n",
        "    end_idx = min((i + 1) * batch_size, len(df))\n",
        "\n",
        "    # Extract the current batch of data\n",
        "    batch_data = df.iloc[start_idx:end_idx].copy()\n",
        "\n",
        "    # Identify categorical columns\n",
        "    categorical_columns = batch_data.select_dtypes(include=['object']).columns\n",
        "\n",
        "    # Encode categorical columns to numerical values\n",
        "    label_encoders = {}\n",
        "    for col in categorical_columns:\n",
        "        label_encoders[col] = LabelEncoder()\n",
        "        batch_data[col] = label_encoders[col].fit_transform(batch_data[col])\n",
        "\n",
        "    # Fill missing values using KNNImputer\n",
        "    imputer = KNNImputer(n_neighbors=5)\n",
        "    batch_data_filled = pd.DataFrame(imputer.fit_transform(batch_data), columns=batch_data.columns)\n",
        "\n",
        "    # Decode back to original categorical values\n",
        "    for col in categorical_columns:\n",
        "        batch_data_filled[col] = label_encoders[col].inverse_transform(batch_data_filled[col].astype(int))\n",
        "\n",
        "    # Append the imputed batch to the DataFrame containing all imputed data\n",
        "    data_filled = pd.concat([data_filled, batch_data_filled], ignore_index=True)\n",
        "\n",
        "# Check if there are any missing values remaining\n",
        "missing_values = data_filled.isnull().sum()\n",
        "print(missing_values,df.info())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kdz_MSBtOP0x"
      },
      "outputs": [],
      "source": [
        "#df = data_filled\n",
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rQYqwQNhynMD"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import plotly.express as px\n",
        "\n",
        "\n",
        "# Sample 5000 random data points\n",
        "df_sampled = df.sample(n=25000, random_state=42)\n",
        "\n",
        "# Plot 3D scatter plot\n",
        "fig = px.scatter_3d(df_sampled, x='j_year', y='i_year', z='ctc', width=500, height=500,\n",
        "                    title='3D Scatter Plot with Sampled Data')\n",
        "fig.update_traces(marker=dict(size=1), selector=dict(mode='markers'))\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ABrssHwA5tF-"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# Plot 3D scatter plot\n",
        "fig = px.scatter_3d(df_sampled, x='position', y='company', z='ctc', width=500, height=500,\n",
        "                    title='3D Scatter Plot with Sampled Data')\n",
        "fig.update_traces(marker=dict(size=1), selector=dict(mode='markers'))\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0ANVA-YE6KJA"
      },
      "outputs": [],
      "source": [
        "sns.pairplot(df_sampled)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OwSB8wXWy8hS"
      },
      "outputs": [],
      "source": [
        "df['position'].to_frame().value_counts()\n",
        "#df['j_year'].head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RORODZxjk4Oj"
      },
      "outputs": [],
      "source": [
        "df.head()\n",
        "df = df_sampled"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2l8e-7s7O6oH"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "feature1 = 'ctc'\n",
        "feature2 = 'company'\n",
        "feature3 = 'position'\n",
        "\n",
        "# Perform clustering (replace with your clustering logic)\n",
        "X = df[[feature1, feature2, feature3]]\n",
        "kmeans = KMeans(n_clusters=3, random_state=42)\n",
        "df['cluster'] = kmeans.fit_predict(X)\n",
        "\n",
        "# Plot 3D scatter plot with clusters as hue\n",
        "fig = plt.figure(figsize=(10, 8))\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "\n",
        "for cluster in df['cluster'].unique():\n",
        "    cluster_df = df[df['cluster'] == cluster]\n",
        "    ax.scatter(cluster_df[feature1], cluster_df[feature2], cluster_df[feature3], label=f'Cluster {cluster}')\n",
        "\n",
        "ax.set_xlabel(feature1)\n",
        "ax.set_ylabel(feature2)\n",
        "ax.set_zlabel(feature3)\n",
        "ax.set_title('3D Scatter Plot with Clustering')\n",
        "ax.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.info(),df.describe)"
      ],
      "metadata": {
        "id": "a9O2os7xlxd6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "# Assuming your dataframe is named 'df'\n",
        "\n",
        "# Define features for clustering\n",
        "features = ['ctc', 'company', 'position']\n",
        "\n",
        "# Perform clustering\n",
        "X = df[features]\n",
        "kmeans = KMeans(n_clusters=3, random_state=42)  # You can adjust the number of clusters\n",
        "df['cluster'] = kmeans.fit_predict(X)\n",
        "\n",
        "# Plot 3D scatter plot with clusters as hue\n",
        "fig = plt.figure(figsize=(10, 8))\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "\n",
        "# Define colors for each cluster\n",
        "colors = ['r', 'g', 'b']\n",
        "\n",
        "for cluster, color in zip(df['cluster'].unique(), colors):\n",
        "    cluster_df = df[df['cluster'] == cluster]\n",
        "    ax.scatter(cluster_df[features[0]], cluster_df[features[1]], cluster_df[features[2]], c=color, label=f'Cluster {cluster}')\n",
        "\n",
        "ax.set_xlabel(features[0])\n",
        "ax.set_ylabel(features[1])\n",
        "ax.set_zlabel(features[2])\n",
        "ax.set_title('3D Scatter Plot with Clustering')\n",
        "ax.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "wTCUbhMAnrZ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "from sklearn.mixture import GaussianMixture\n",
        "\n",
        "# Assuming your dataframe is named 'df'\n",
        "\n",
        "# Define features for clustering\n",
        "features = ['ctc', 'company', 'position']\n",
        "\n",
        "# Perform clustering with GMM\n",
        "X = df[features]\n",
        "gmm = GaussianMixture(n_components=3, covariance_type= 'tied',random_state=42)  # You can adjust the number of components (clusters)\n",
        "df['cluster'] = gmm.fit_predict(X)\n",
        "\n",
        "# Plot 3D scatter plot with clusters as hue\n",
        "fig = plt.figure(figsize=(10, 8))\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "\n",
        "# Define colors for each cluster\n",
        "colors = ['r', 'g', 'b','y','c']\n",
        "\n",
        "for cluster, color in zip(df['cluster'].unique(), colors):\n",
        "    cluster_df = df[df['cluster'] == cluster]\n",
        "    ax.scatter(cluster_df[features[0]], cluster_df[features[1]], cluster_df[features[2]], c=color, label=f'Cluster {cluster}')\n",
        "\n",
        "ax.set_xlabel(features[0])\n",
        "ax.set_ylabel(features[1])\n",
        "ax.set_zlabel(features[2])\n",
        "ax.set_title('3D Scatter Plot with Clustering')\n",
        "ax.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "E2CnY6iaoG7h"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPjtl6jkOO9CNFPE67NEtTc",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}